# LLMs

This repository consists of methods to run LLMs in PyTorch, ONNX and Llama.cpp with operators dispatch to NPU.

This is an early access flow, and expected to be upgraded in upcoming release. 

## Run LLMs

* [LLMs on RyzenAI with Pytorch](./models/llm/docs/README.md)
* [Speculative Decoding of LLMs in Pytorch](./models/llm_assisted_generation/README.md)
* [LLMs on RyzenAI with ONNX](./models/llm_onnx/docs/README.md)
* [LLMs on RyzenAI with llama.cpp](./models/llm_gguf/docs/README.md)



